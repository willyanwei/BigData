# HBase

## 大数据学习线路图

<img src="https://upload-images.jianshu.io/upload_images/22827736-ab17271698b9385a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="70%">

## 什么是HBase
  
* Hadoop DataBase  
	* 建立在Hadoop文件系统之上的面向列的NoSQL分布式数据库
	* 提供对数据的随机实时读写访问
	* Hbase利用HDFS作为其文件存储系统
	* Hbase利用MR来处理Hbase中的海量数据

## 为什么需要HBase

* Hadoop已经有了HDFS和MR，为什么还需要HBase？  
	* MR可以很好的解决大规模数据离线批量处理的问题，但是只能以顺序方式访问数据，实时性很差
	* 需要一个新的解决方案，能够随机访问数据中的任何单元----Hadoop随机存取数据库HBase

* 为什么不用传统的关系型数据库？
	* 传统的通用关系型数据库无法应对数据规模剧增时导致的系统扩展性和性能问题，分库分表也不能很好的解决
	* 传统的关系型数据库在数据结构发生变化时，一般需要停机维护，空列也会浪费存储空间  

**HDFS数据不方便日常使用，查询也慢**  
HDFS相当于我们日常办公用的文件系统，存放着各种文件；Hbase相当于日常用的数据库，存放着各种表。在我们进行数据使用时，显然数据表更方便些。

## HBase的使用场景
* 历史数据存储类应用（70%）
	* 历史订单，历史记录，日志类
	* 这些业务的数据量巨大，传统数据库难以hold住，而这类应用往往查询量相对较小，查询随机性较大，对于mysql，redis来说存储成本太高，HBase非常合适
* 分析型应用（20%）
	* 配合MR,Spark，Storm来做数据分析
* 在线读写型应用（10%）
	* 以理解为对mysql或者redis的一种替换做法，但是这类应用比较在意可用性、稳定性以及sql、索引等支持。
	* hbase的劣势较大，应用范围较窄。只有在一种情况下会是用--mysql或者redis的容量实在无法支撑数据量了，而应用对可用性的要求可以有一定成都的容忍。

## HBase的优缺点

* 优点
	* 写入性能高，几乎可以无限扩展
	* 海量数据下（100TB级别表）的查询仍然能保持在5ms级别
	* 存储容量大，不需要做分库分表，维护简单
	* 标的列可以灵活配置，一行可以有多个非固定的列

* 缺点
	* 并不能保证100%时间可用，宕机恢复时间根据写入流量不同，在几秒到几十秒内
	* **查询便利性上缺少SQL语句支持**
	* 无索引，查询必须按照RowKey严格查询，不带RowKey的Filter性能较低
	* 对于查询会有一些毛刺，特别是compact时，平均查询延迟在2~3ms，但是毛刺时会升高到几十到100多MS

## HBase数据模型

<img src="https://upload-images.jianshu.io/upload_images/22827736-3b6242fc4cc03e72.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="70%">



<img src="https://upload-images.jianshu.io/upload_images/22827736-5058acd549be1c72.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="70%">

* RowKey
	* RowKey的概念和mysql中的主键是完全一样的，HBase使用RowKey来唯一区分某一行的数据
	* HBase只支持三个查询方式
		* 基于RowKey的单行查询
		* 基于RowKey的范围扫描，查询RowKey2~RowKey5之间的数据
		* 全表扫描
	所以，RowKey对HBase的性能影响非常大
	* RowKey行键可以是任意字符串，最大长度64KB，实际应用中长度一般为10-100bytes，不宜过大，每个列簇的物理文件中都会存储一个RowKey
* Cloumn
	* 列，可以理解为mysql的列，指定列名列值
	* 没有严格的表结构，分散的
* Column Family
	* 列簇，HBase通过列簇划分数据的存储，列簇下面包含任意多的列，实现数据灵活的存取，列簇由一个一个列组成
	* HBase表创建的时候就必须指定列簇，就像关系型数据库创建的时候必须指定具体的列一样
	> HBase的列簇不是越多越好？
	> 官方推荐列簇最好<=3个  
	> 常用的场景一般是一个列簇  
	> 列簇是HBase存储的物理切分单位，可以理解为一个列簇存储一个文件，列簇越多，存储的文件个数越多，扫描时扫描文件越多，效率越低

	> 什么样的列划分到一个列簇中？  
	> 具有相同特性（通常情况下会一起访问的列），例如查询个人信息时name-age-sex-num等会放到同一个列簇中
	> 如果特性类别特别多，会强制合并到一个列簇中，保证簇不超过3个


* TimeStamp
	* 在数据进行插入时，每插入一条数据就会自动生成一个时间戳，时间戳的作用就是记录数据的版本
	* 是实现HBase多版本的关键，在HBase总使用不同的timestamp来标识相同RowKey行对应的不同版本数据
	* 时间戳默认是系统时间，也可以手动指定

* Cell单元格
	* HBase通过RowKey和Column确定的一个存储单元称为Cell
	* 每一个Cell都保存着同一份数据的多个版本，版本通过时间戳来索引
	* 每个Cell中不同版本的数据按照时间倒序排列，即最新的数据排在最前面
	> 为了避免数据存在过多版本造成的管理负担，包括存储和索引负担，HBase提供了两个数据版本回收方式：  
	> 1. 保存数据的最后N个版本  
	> 2. 保存最近一段时间内的版本（设置数据生命周期TTL）  
	> 3. 用户可以针对每个列簇进行设置，由{rowkey，column（=+），version}唯一确定的单元  
	> Cell中的数据是没有类型的，全部由字节码形式存储  

## HBase的设计原则   
HBase是三维有序存储的，通过rowkey（行键），column key（column family和qualifier）和TimeStamp（时间戳）这个三个维度可以对HBase中的数据进行快速定位。
 
* RoeKey设计原则 

	* 长度原则
		rowkey是一个二进制码流，可以是任意字符串，最大长度64kb ，实际应用中一般为10-100bytes，以byte[] 形式保存，一般设计成定长。

		建议越短越好，不要超过16个字节，原因如下：

		* 数据的持久化文件HFile中是按照KeyValue存储的，如果rowkey过长，比如超过100字节，1000w行数据，光rowkey就要占用100*1000w=10亿个字节，将近1G数据，这样会极大影响HFile的存储效率；
		* MemStore将缓存部分数据到内存，如果rowkey字段过长，内存的有效利用率就会降低，系统不能缓存更多的数据，这样会降低检索效率。
		* 目前操作系统都是64位系统，内存8字节对齐，控制在16个字节，8字节的整数倍利用了操作系统的最佳特性。
	* 唯一原则  
		* 不能重复
	* 散列原则  
		* 如果rowkey按照时间戳的方式递增，不要将时间放在二进制码的前面，建议将rowkey的高位作为散列字段，由程序随机生成，低位放时间字段，这样不管时间先后，将数据均衡分布在每个HRegionServer，以实现负载均衡的几率。  
		* 如果没有散列字段，首字段直接是时间信息，所有的数据都会集中在一个RegionServer上，这样在数据检索的时候负载会集中在个别的RegionServer上，造成热点问题，会降低查询效率。
		
		> 常见的避免热点的方法以及它们的优缺点：
		> 
		> * 随机前缀
		> 
		> 这里所说的加盐不是密码学中的加盐，而是在rowkey的前面增加随机数，具体就是给rowkey分配一个随机前缀以使得它和之前的rowkey的开头不同。分配的前缀种类数量应该和你想使用数据分散到不同的region的数量一致。加盐之后的rowkey就会根据随机生成的前缀分散到各个region上，以避免热点。
		> 
		> * 哈希
		> 
		> 哈希会使同一行永远用一个前缀加盐。哈希也可以使负载分散到整个集群，但是读却是可以预测的。使用确定的哈希可以让客户端重构完整的rowkey，可以使用get操作准确获取某一个行数据
		> 
		> * 反转
		> 
		> 第三种防止热点的方法时反转固定长度或者数字格式的rowkey。这样可以使得rowkey中经常改变的部分（最没有意义的部分）放在前面。这样可以有效的随机rowkey，但是牺牲了rowkey的有序性。
		> 
		> 反转rowkey的例子以手机号为rowkey，可以将手机号反转后的字符串作为rowkey，这样的就避免了以手机号那样比较固定开头导致热点问题
		> 
		> * 时间戳反转
		> 
		> 一个常见的数据处理问题是快速获取数据的最近版本，使用反转的时间戳作为rowkey的一部分对这个问题十分有用，可以用Long.Max_Value - timestamp 追加到key的末尾，例如[key][reverse_timestamp] ,[key] 的最新值可以通过scan[key]获得[key]的第一条记录，因为HBase中rowkey是有序的，第一条记录是最后录入的数据。
		> 

## HBase架构  



HBase与Hadoop的关系  
HDFS为HBase提供可靠的底层存储支撑  
MR为HBase提供高性能计算能力  
<img src="https://upload-images.jianshu.io/upload_images/22827736-cab11be0cdccaebb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="70%">



HBase中每张表都按照一定的范围被分割成多个子表HRegion，  
默认一个HRegion超过256M就要被分割成两个，  
HRegion由HRegionServer管理  

<img src="https://upload-images.jianshu.io/upload_images/22827736-e0f89909bfb1a263.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="70%">


* Client  
Client 是整个HBase系统的入口，客户端使用RPC协议与HMaster和HRegionServer进行通信
	* 对于管理类表的增删操作，Client与HMaster进行RPC交互
	* 对于数据读写操作Client与HRegionServer进行RPC交互
客户端可以有多个，也可以以不同形式访问，例如JAVA接口，HBase shell命令行，Avro等
* ZooKeeper
	* 存储HBase元数据信息
	* 实时监控RegionServer
	* 存储所有Region的寻址入口
	* 保证HBase中只有一个HMaster节点，通过ZK的选举机制来选出HMaster
* HMaster 主
	* 管理用户对表的增删改查工作
	* 管理HRS的负载均衡负载均衡，调整Region的分布
	* 在RegionSplit（分裂）后，负责新Region的分配
	* 在HRS停机后，负责失效
	* HRS上Region的迁移
* HRegionServer 从  
	* 主要负责响应用户的I/O，向HDFS读写数据
	* HRS内部管理了一系列的HRegion对象
	* 每个HRegion对应表中的一个Region
	* HRegion由多个HStore组成
	* 每个HStore对应表中的一个ColumnFamily的存储
	> store存储是HBase的存储核心，由两部分组成：  
	> 
	> * MemStore：用户写入的数据首先会放入MemStore，大小为64M
	> * StoreFiles：当MemStore满了以后会Flush成一个StoreFile,当StoreFile文件数量增长到一定阈值，会触发Compact合并操作，将多个StoreFile合并成一个StoreFile，合并过程中进行版本合并和数据删除，HBase其实只有增加数据，所有的更新和删除操作都是在后续compact过程中进行 

* HLog  
	* HLog用来存储数据日志
	* HBase系统故障恢复和主从复制都是基于HLog实现的：  
		* 所有的写入操作（写入更新删除）的数据都先以追加方式写入HLog，再写入MemStore
		* 大多数情况HLog并不会被读取，但如果HRS在某些异常情况下发生宕机，此时已经写入MemStore但尚未Flush到磁盘的数据就会丢失，需要回放HLog补救丢失的数据。
		* 此外HBase主从复制需要主集群将HLog日志发送给从集群，从集群在本地执行回放操作，完成集群之间的数据复制  

	* HLog生命周期
	HLog文件生成之后并不会永久存储在系统中，它的使命完成后，文件就会失效最终被删除。
		* HLog构建
		HBase的任何写入（更新删除）操作都会先将记录追加写入到HLog中。
		* HLog回滚  
		HBase后台启动一个线程，每隔一段时间（由参数“hbase.regionserver. logroll.period”决定，默认一小时）进行日志回滚。
		日志回滚会新建一个新的日志文件，接收新的日志数据  
		日志回滚机制主要是为了方便过期日志数据能够以文件形式直接删除  
		* HLog失效  
		写入数据一旦从MemStore中落盘，对应的日志文件就会失效  
		为了方便处理，日志失效删除总是以文件为单位执行  
		查看某个HLog文件是否失效，只需要确认该HLog文件中所有的日志记录对应的数据是否已经完成落盘，如果已落盘，则日志文件失效  
		一旦日志文件失效，就会从WALs文件夹移动到oldWALs文件夹，注意此时HLog文件并没有被系统删除  
		* HLog删除
		Master后台会启动一个线程，每隔一段时间（参数'hbase.master.cleaner. interval'，默认1分钟）检查一次文件夹oldWALs下的所有失效日志文件，确认是否可以删除，确认可以删除之后执行删除操作。  
		确认条件主要有两个：
			* 该HLog文件是否还在参与主从复制。对于使用HLog进行主从复制的业务，需要继续确认是否该HLog还在应用于主从复制。
			* 该HLog文件是否已经在OldWALs目录中存在10分钟。为了更加灵活地管理HLog生命周期，系统提供了参数设置日志文件的TTL（参数'hbase.master.logcleaner.ttl'，默认10分钟），默认情况下oldWALs里面的HLog文件最多可以再保存10分钟。

## HBase数据在HDFS存储  
Hbase在hdfs上的存储位置，根目录是由配置项hbase.rootdir决定，假设设置的是"/hbase" ，在ambari集群可以通过Advanced hbase-site->HBase root directory参数进行配置  
* /hbase/WALs  
在该目录下，对于每个RegionServer，都会对应1~n个子目录  
 
* /hbase/oldWALs  
当/hbase/WALs中的HLog文件被持久化到存储文件时，它们就会被移动到/hbase/oldWALs  

* /hbase/hbase.id  
集群的唯一ID  

* /hbase/hbase.version  
集群的文件格式版本信息  

* /hbase/corrupt  
损坏的日志文件，一般为空  

* /hbase/archive  
存储表的归档和快照，HBase 在做 split或者 compact 操作完成之后，会将 HFile 移到archive 目录中，然后将之前的 HFile 删除掉，该目录由 HMaster 上的一个定时任务定期去清理。

* /hbase/.tmp  
当对表做创建或者删除操作的时候，会将表move 到该 tmp 目录下，然后再去做处理操作。  

* /hbase/data  
hbase存储数据的核心目录  
	* /hbase/data/hbase  
	该目录存储了存储了 HBase 的 namespace、meta 和acl 三个系统级表。  
	namespace 中存储了 HBase 中的所有 namespace 信息，包括预置的hbase 和 default。acl 则是表的用户权限控制。    
	/hbase/data/hbase/meta；    
	/hbase/data/hbase/namespace；  
	/hbase/data/hbase/acl

	* /hbase/data/库名  
		* /hbase/data/库名/表名/.tabledesc
		表的元数据信息

		* /hbase/data/库名/表名/.tabledesc/.tableinfo.0000000001  
		表的元数据信息具体文件

		* /hbase/data/库名/表名/.tmp  
		中间临时数据，当.tableinfo被更新时该目录就会被用到

		* /hbase/data/库名/表名/01a10fbfc443c8a91766ccea497ce4ee  
		是由region的表名+Start Key+时间戳产生的HashCode

		* /hbase/data/库名/表名/region名/.regioninfo  
		包含了对应region的HRegionInfo的序列化信息，类似.tableinfo。hbase hbck 工具可以用它来生成丢失的表条目元数据

		* /hbase/data/库名/表名/region名/列族名  
		每个列族的所有实际数据文件

		* /hbase/data/库名/表名/region名/列族名/文件名  
		hbase实际数据文件

		* /hbase/data/库名/表名/region名/.tmp  
		存储临时文件，比如某个合并产生的重新写回的文件(compaction操作时合并文件写到.tmp下)。

## 数据寻址

* HBase如何实现快速查询？  
	* 底层数据存储在HDFS
	* HBase以Region进行存储
	* Region按照行方向进行切分的，按照RowKey
	* Region可以理解为HDFS上的数据指针
	* 数据量越大，Region会越多，如果没有索引机制，需要全表扫描，扫描所有Region  
	> * .meta表  
	> 		原始数据region的索引，包括
	> 			* 存储节点
	> 			* RegionID
	> 			* 启始的RowKey
	> 			* 结束的RowKey  
	> 		一个Region会在.meta表中对应一条数据  
	> 		.meta表也需要存储，可以理解为HBase中一个表，仍然以Region为存储  
	> 		.meta表超过10G后也开始进行分裂
	> 
	> * -root- 表  
	> 		是.meta表的索引表，主要记录.meta表所在的Region信息，不会再进行分裂无论多大  
	> 		-root-表的Region地址存储在ZooKeeper中/hbase/meta-region-server

	* 用户进行检索
	先检索.meta获取真正的数据存储在哪个Region，用户就可以访问数据了

* 检索数据的流程  
	* 在 HBase-0.96 版本以前  
	客户端--ZK获取-root-地址--.meta地址--原始数据的地址  
		* Client 请求 ZooKeeper 获得-ROOT-所在的 RegionServer 地址
		* Client 请求-ROOT-所在的 RS 地址，获取.META.表的地址，Client 会将-ROOT-的相关信息 cache 下来，以便下一次快速访问
		* Client 请求.META.表的 RegionServer 地址，获取访问数据所在 RegionServer 的地址，Client 会将.META.的相关信息 cache 下来，以便下一次快速访问
		* Client 请求访问数据所在 RegionServer 的地址，获取对应的数据

		> 从上面的路径我们可以看出，用户需要 3 次请求才能知道用户 Table 真正的位置，这在一定程序带来了性能的下降。  
		> 在 0.96 之前使用 3 层设计的主要原因是考虑到元数据可能需要很大。但是真正集群运行，元数据的大小其实很容易计算出来。在 BigTable 的论文中，每行METADATA 数据存储大小为 1KB 左右，如果按照一个 Region 为 128M 的计算，3 层设计可以支持的 Region 个数为 2^34 个，采用 2 层设计可以支持 2^17（131072）。那么 2 层设计的情况下一个集群可以存储 4P 的数据。这仅仅是一个 Region 只有 128M 的情况下。如果是 10G呢? 因此，通过计算，其实 2 层设计就可以满足集群的需求。因此在 0.96 版本以后就去掉了-ROOT-表了。

	* 在 HBase-0.96 版本以后  
	2层结构其实完全能满足业务的需求，因此 0.96 版本以后将-ROOT-表去掉了。
		* Client请求ZK获取.meta所在的HRS的地址
		* Client请求.meta 所在的HRS获取访问数据所在的HRS地址，Client会把.meta的相关信息cache下来，以便下次快速访问  
		* Client请求数据所在的HRS，获取所需要的数据 
		> 去掉-root-表的原因：  
		> 提高性能  
		> 2层结构以及可以满足集群的需求  




## HBase的读写		
* 写过程  
	* Client先从缓存中定位Region，如果没有缓存则需要访问ZK，从.meta表中获取需要写入的Region信息
	* 找到小于RowKey并最接近RowKey的StartKey对应的Region
	* 将更新写入WAL中。当客户端发起put/delete请求时，考虑到写入内存会有丢失数据的风险。在写入缓存前，HBase会先写入到Write Ahead Log（WAL）中，WAL存储在HDFS。那么及时发生宕机，也可以通过WAL还原初始数据。
	* 将更新写入memstore，当增加到一定的大小，达到预设的Flush Size阈值时，会触发Flush MemStore，把MemStore中的数据写出到HDFS上，生成一个storefile
	* 随着StoreFile文件的不断增多，当增长到一定阈值后，触发compact合并操作，将多个storefile合并成一个，同时进行版本合并和数据删除
	* StoreFile通过不断的compact合并操作，逐步形成越来越大的storefile
	* 单个storefile大小超过一定阈值以后，触发Split操作，把当前Region拆分成两个，新拆分的两个Region会被HMaster分配到对应的两个HRS上

* 读过程
	* Client先从缓存中定位Region，如果缓存中找不到，则需要访问ZK，查询-ROOT-表，获取-root-表所在的HRS地址
	* 通过查询-root-的Region服务器获取含有-meta-表所在的HRS地址
		> 在 HBase-0.96 版本以后，去除了-root-表
	* Client会将保存有HRS位置信息的元数据表.meta进行缓存，然后在表中确定待检索RowKey所在的HRS信息
	* Client会向.meta表中确定的RHRS发送真正的数据读取请求 
	* 数据读取先从MemStore中找，如果没有再从StoreFile中找

* 为什么HBase写比读快？ 
	HBase底层存储引擎为LSM-Tree。 LSM-Tree全称是Log Structured Merge Tree，是一种分层，有序，面向磁盘的数据结构，其核心思想是充分了利用了，磁盘批量的顺序写要远比随机写性能高出很多。   
	LSM的核心思想就是放弃部分读能力，换取写入的最大化能力。    
	假设内存足够大，因此不需要每次有新的数据更新就必须写入到磁盘，而是先将数据留在内存中，等积累到足够多之后，再使用合并并排序的方式将内存中的数据合并追加到磁盘队尾（因为所有待排序的树都是有序的，可以通过合并排序的方式快速合并在一起）。    
	另外写入的时候将随机写入转换成顺序写入，数据写入速度也很稳定。    


	* LSM树  
	Log-Structured-Merge-Tree  
	牺牲了读性能，提高了写性能（与mysql等关系型数据库对比）
  
		* 为什么说提升了写性能：  
	LSM原理：  
	将对数据的修改增量保存在内存中，达到指定大小限制之后，批量把数据flush到磁盘中，磁盘中的树定期做merge操作，合并成一个大树
	
		* 为什么说牺牲了读性能？ 
			* 其实HBase读取速度并不慢  
				* LSM-Tree(Log-Structured Merge-Tree) + HTable(region分区) + Cache 架构  
				客户端可以直接定位到要查数据所在的HRegion server服务器，然后直接在服务器的一个region上查找要匹配的数据，并且这些数据部分是经过cache缓存的。
				* rowkey是排序的
				* 数据按列存储

			* 但是相比较于关系型数据库，如MYSQL用的B+树来说，读的性能降低了一个数量级：  
			读取数据时，HBase读取首先会在缓存（BlockCache）中查找，它采用了LRU（最近最少使用算法），  
			如果缓存中没找到，会从内存中的MemStore中查找，  
			只有这两个地方都找不到时，才会加载HFile中的内容，而读取HFile速度也会很快，因为节省了寻道开销

	
			> 关系型数据库读为什么快？B+树为什么读性能快？  
			> 1. B+树可以理解为扁且宽，也就是层数少，每层的节点数目很多。但是每层的节点多归多，却不存储数据，只起到索引效果，所有的数据都存在叶子节点上  
			> 2. B+树所有的Data域在叶子节点，一般来说都会进行一个优化，就是将叶子节点用指针串起全部数据，这样就能进行区间访问了  
			> 3. 查询效率主要是通过I/O次数来判断：B+树中，层数少，只有叶子节点存数据，这些特点能够保证磁盘I/O次数少，效率高  


# Hbase 操作
* HBase包含可以与HBase进行通信的Shell。 HBase使用Hadoop文件系统来存储数据。它拥有一个主服务器和区域服务器。数据存储将在区域(表)的形式。这些区域被分割并存储在区域服务器。
主服务器管理这些区域服务器，所有这些任务发生在HDFS。
	* 下面给出的是一些由HBase Shell支持的命令。通用命令  
	status: 提供HBase的状态，例如，服务器的数量。  
	version: 提供正在使用HBase版本。  
	table_help: 表引用命令提供帮助。   
	whoami: 提供有关用户的信息。  

	* 数据定义语言， 这些是关于HBase在表中操作的命令。  
	create: 创建一个表。   
	list: 列出HBase的所有表。  
	disable: 禁用表。  
	is_disabled: 验证表是否被禁用。  
	enable: 启用一个表。  
	is_enabled: 验证表是否已启用。   
	describe: 提供了一个表的描述。  
	alter: 改变一个表。  
	exists: 验证表是否存在。  
	drop: 从HBase中删除表。  
	drop_all: 丢弃在命令中给出匹配“regex”的表。  
	* Java Admin API: 在此之前所有的上述命令，Java提供了一个通过API编程来管理实现DDL功能。在这个org.apache.hadoop.hbase.client包中有HBaseAdmin和HTableDescriptor 这两个重要的类提供DDL功能。  

	* 数据操纵语言
	put: 把指定列在指定的行中单元格的值在一个特定的表。  
	get: 取行或单元格的内容。  
	delete: 删除表中的单元格值。  
	deleteall: 删除给定行的所有单元格。    
	scan: 扫描并返回表数据。    
	count: 计数并返回表中的行的数目。    
	truncate: 禁用，删除和重新创建一个指定的表。     
	
	* Java client API: 在此之前所有上述命令，Java提供了一个客户端API来实现DML功能，CRUD（创建检索更新删除）操作更多的是通过编程，在org.apache.hadoop.hbase.client包下。 在此包HTable 的 Put和Get是重要的类。  

	启动 HBase Shell  
	要访问HBase shell，必须导航进入到HBase的主文件夹。  
	cd /usr/localhost/  
	cd Hbase  
	可以使用“hbase shell”命令来启动HBase的交互shell，如下图所示。  
	./bin/hbase shell  
	如果已成功在系统中安装HBase，那么它会给出 HBase shell 提示符，如下图所示。  
	HBase Shell; enter 'help<RETURN>' for list of supported commands.Type   "exit<RETURN>" to leave the HBase ShellVersion 0.94.23,   rf42302b28aceaab773b15f234aa8718fff7eea3c, Wed Aug 2700:54:09 UTC 2014  

	hbase(main):001:0>    
	要退出交互shell命令，在任何时候键入 exit 或使用<Ctrl + C>。进一步处理检查shell功能之前，使用 list 命令用于列出所有可用命令。list是用来获取所有HBase 表的列表。首先，验证安装HBase在系统中使用如下所示。  
	hbase(main):001:0> list  
	当输入这个命令，它给出下面的输出。  
	hbase(main):001:0> list  
	TABLE  
 
# HDFS->HBase    
Hbase数据在HDFS的存储的，存储位置通过hbase-site.xml配置文件来设置：
     <property>  
      <name>hbase.rootdir</name>  
      <value>/apps/hbase/data</value>    
    </property>


例如：

/apps/hbase/data/default/HBase_Student/

Hbase shell客户端登陆

root@101Server:/opt/hbase2.4/bin# hbase shell


Hbase从hdfs导入数据：

* 场景一： 将HDFS上的文件中的数据导入到hbase中

注意： 这里的HDFS数据是从HBASE导出的

实现上面的需求也有两种办法，一种是自定义mr，一种是使用hbase提供好的import工具

hbase org.apache.hadoop.hbase.mapreduce.Import HDFS2HBASE /case/HBase2HDFS

 

* 场景二：

	* hdfs中的数据是这样的

		每一行的数据是这样的
		[root@hadoop26 ~]# hadoop fs  -cat /case/hdfs_student.txt  
		id 	name 		age 		gender 		birthday

		0001        Tom        18        Male                 80        90        85        T2

		0002        Amy        19                 01        95                 89        T1

		0003        Allen        19        Male        02        90                 88        T1


	* 使用habse提供的import工具

		首先查看其用法

		在hbase中创建表table2

		hbase(main):016:0> create 'HDFS2HBase_Student','StuInfo','Grades'

		0 row(s) in 0.4080 seconds

		=> Hbase::Table - table2

		在命令中使用命令进行导入

		/opt/hadoop3.2/bin/yarn jar /opt/hbase2.4/lib/hbase-server-2.4.11.jar importtsv \

		 -Dimporttsv.columns=HBASE_ROW_KEY,StuInfo:Name,StuInfo:Age,StuInfo:Sex,StuInfo:Class,Grades:BigData,Grades:Computer,Grades:Math  HDFS2HBase_Student \

		hdfs://101Server:9000/case/student.csv

		查看table2中的数据

		hbase(main):018:0> scan 'HDFS2HBase_Student'
		ROW                       COLUMN+CELL

                                                                                                                               

# HIVE 和 Hbase 整合

* hive和Hbase的整合使得hive能够操作Hbase的数据表  
	* Hive是建立在Hadoop之上的数据仓库基础构架、是为了减少MapReduce编写工作的批处理系统，Hive本身不存储和计算数据，它完全依赖于HDFS和MapReduce。Hive可以理解为一个客户端工具，将我们的sql操作转换为相应的MapReduce jobs，然后在Hadoop上面运行。   
	* HBase全称为Hadoop Database，即HBase是Hadoop的数据库，是一个分布式的存储系统。HBase利用Hadoop的HDFS作为其文件存储系统，利用Hadoop的MapReduce来处理HBase中的海量数据。利用Zookeeper作为其协调工具。   
	* HBase数据库的缺点在于——语法格式异类，没有类sql的查询方式，因此在实际的业务当中操作和计算数据非常不方便，但是Hive就不一样了，Hive支持标准的sql语法，于是我们就希望通过Hive这个客户端工具对HBase中的数据进行操作与查询，进行相应的数据挖掘，这就是所谓Hive与hBase整合的含义。


	> 整合后：   
	> select * from table   
	> group by word    
	> order by word;
