# 大数据各组件存在的意义  

## 为什么需要HDFS  
随着区块链、大数据等技术的推动，全球数据量正在无限制地扩展和增加。  
随着数据量越来越大，在一个操作系统存不下所有的数据，那么就分配到更多的操作系统管理的磁盘中，但是不方便管理和维护，迫切需要一种系统来管理多台机器上的文件，这就是分布式文件管理系统。HDFS只是分布式文件管理系统中的一种。  

## 为什么需要MapReduce？  
MR适合在大量计算机组成的分布式并行环境里进行数据处理  

## 为什么需要HBase
* Hadoop已经有了HDFS和MR，为什么还需要HBase？  
	* MR可以很好的解决大规模数据离线批量处理的问题，但是只能以顺序方式访问数据，实时性很差
	* 需要一个新的解决方案，能够随机访问数据中的任何单元----Hadoop随机存取数据库HBase

* 为什么不用传统的关系型数据库？
	* 传统的通用关系型数据库无法应对数据规模剧增时导致的系统扩展性和性能问题，分库分表也不能很好的解决
	* 传统的关系型数据库在数据结构发生变化时，一般需要停机维护，空列也会浪费存储空间  
**HDFS数据不方便日常使用，查询也慢**

## 为什么需要Pig/Hive 
有了MapReduce，Tez和Spark之后，程序员发现，MapReduce的程序写起来真麻烦,希望能简化这个过程。这就好比你有了汇编语言，虽然你几乎什么都能干了，但是你还是觉得繁琐。你希望有个更高层更抽象的语言层来描述算法和数据处理流程。于是就有了Pig和Hive。  
Pig是接近脚本方式去描述MapReduce，Hive则用的是SQL。它们把脚本和SQL语言翻译成MapReduce程序，丢给计算引擎去计算，而你就从繁琐的MapReduce程序中解脱出来，用更简单更直观的语言去写程序了

这里重点来看下Hive，Hive用的是SQL，更容易上手
1. HDFS解决分布式存储问题，MR解决分布式计算问题
但是学习过程很痛苦，需要一定的编程基础-JAVA,Linux，MR编程，MR套路和原理  
在Hadoop编程过程中，在解决计算问题的时候，基本都是针对结构化数据，事实上在实际生产过程中接触到的数据比如日志数据，是比较规整的结构化数据，针对结构化数据最好的分析方式是SQL  
比如JION操作，实现两表的关联
如果使用MR编程，至少要写60行代码
如果使用SQL只需一行：
select * from a join b on a.pid = b.pid  

## 为什么要有Impala  
有了Hive之后，人们发现SQL对比Java有巨大的优势。一个是它太容易写了。比如统计词频，用SQL描述就只有一两行，MapReduce写起来大约要几十上百行。  
而更重要的是，非计算机背景的用户终于感受到了爱：我也会写SQL于是数据分析人员终于从乞求工程师帮忙的窘境解脱出来，工程师也从写奇怪的一次性的处理程序中解脱出来。大家都开心了。  Hive逐渐成长成了大数据仓库的核心组件。甚至很多公司的流水线作业集完全是用SQL描述，因为易写易改，一看就懂，容易维护。
但是
自从数据分析人员开始用Hive分析数据之后，它们发现，Hive在MapReduce上跑，真慢!流水线作业集也许没啥关系，比如24小时更新的推荐，反正24小时内跑完就算了。数据分析，人们总是希望能跑更快一些。对于一个巨型网站海量数据下，这个处理过程也许要花几十分钟甚至很多小时。而这个分析也许只是你万里长征的第一步，还需要再快点!

于是Impala，Presto，Drill等交互SQL引擎诞生了。  
系统的核心理念是，MapReduce引擎太慢，因为它太通用，太强壮，太保守，我们SQL需要更轻量，更激进地获取资源，更专门地对SQL做优化，而且不需要那么多容错性保证(因为系统出错了大不了重新启动任务，如果整个处理时间更短的话，比如几分钟之内)。这些系统让用户更快速地处理SQL任务，牺牲了通用性稳定性等特性。如果说MapReduce是大砍刀，砍啥都不怕，那上面三个就是剔骨刀，灵巧锋利，但是不能搞太大太硬的东西


## 为什么要整合Hbase和Hive  
* hive和Hbase的整合使得hive能够操作Hbase的数据表  
	* Hive是建立在Hadoop之上的数据仓库基础构架、是为了减少MapReduce编写工作的批处理系统，Hive本身不存储和计算数据，它完全依赖于HDFS和MapReduce。Hive可以理解为一个客户端工具，将我们的sql操作转换为相应的MapReduce jobs，然后在Hadoop上面运行。   
	* HBase全称为Hadoop Database，即HBase是Hadoop的数据库，是一个分布式的存储系统。HBase利用Hadoop的HDFS作为其文件存储系统，利用Hadoop的MapReduce来处理HBase中的海量数据。利用Zookeeper作为其协调工具。   
	* HBase数据库的缺点在于——语法格式异类，没有类sql的查询方式，因此在实际的业务当中操作和计算数据非常不方便，但是Hive就不一样了，Hive支持标准的sql语法，于是我们就希望通过Hive这个客户端工具对HBase中的数据进行操作与查询，进行相应的数据挖掘，这就是所谓Hive与hBase整合的含义。  

## 为什么要Spark  
* MapReduce模型的痛点:  MR主要适用于批处理  
	* 不擅长实时计算
	MapReduce无法像MySQL一样，在毫秒或者秒级内返回结果。
	* 不擅长流式计算
	流式计算的输入数据是动态的，而MapReduce的输入数据集是静态的，不能动态变化。这是因为MapReduce自身的设计特点决定了数据源必须是静态的。
	* 不擅长DAG（有向图）计算  
	DAG：多个应用程序存在依赖关系，后一个应用程序的输入为前一个的输出。  
	在这种情况下，MapReduce并不是不能做，而是使用后，每个MapReduce作业的输出结果都会写入到磁盘，会造成大量的磁盘IO，导致性能非常的低下。
* Spark适用于各种各样原先需要多种不同的分布式平台的场景
	* 批处理--Spark
	* 迭代算法--从某个值开始，不断地由上一步的结果计算（或推断）出下一步的结果
	* 交互式查询--SparkSQL，提供易使用的交互式查询语言，如SQL.DBMS负责执行查询命令，并将查询结果显示在屏幕上
	* 流处理--SparkStreaming   

## 为什么使用SparkSQL  
HIVESQL-MR: HIVE，将HiveSQL转换成MR然后提交到集群上执行，大大简化了编写MR的程序复杂性
SparkSQL-SQL-RDD：SparkSQL，将SQL查询转换成SparkCore的应用程序，然后提交到集群执行
SparkSQL是一个统一的数据处理技术栈，spark整体hive，可以无缝处理hive数据仓库中的数据  

## 为什么要有SparkStreaming 

提到spark streaming，我们就必须了解一下BDAS（Berkeley Data Analytics Stack），这个伯克利大学提出的关于数据分析的软件栈。  
从它的视角来看，目前的大数据处理可以分为如下三个类型：  
1. **复杂的批量数据处理**（batch data processing），通常的时间跨度在数十分钟到数小时之间；  
2. **基于历史数据的交互式查询**（interactive query），通常的时间跨度在数十秒到数分钟之间；  
3. **基于实时数据流的数据处理**（streaming data processing），通常的时间跨度在数百毫秒到数秒之间；  

目前已经有很多相对成熟的开源软件来处理以上三种情况：   
1. MapReduce来进行批量数据处理；  
2. Impala进行交互式查询；  
3. 对于流式数据处理，我们可以采用storm  
  
对于大多数互联网公司来说，一般都会同时遇到以上三种数据处理情况，那么在使用的过程中这些公司可能会遇到如下的不便：  
1. 三种情况的输入输出数据无法无缝共享，需要进行格式相互转换  
2. 每个开源软件需要一个开发和维护团队，提高了成本  
3. 在同一个集群中对各个系统协调资源分配比较困难  

BDAS就是以Spark为基础的一套软件栈，利用基于内存的通用计算模型将以上三种场景一网打尽，同时支持Batch、Interactive、Streaming的处理，且兼容支持HDFS和S3等分布式文件系统，可以部署在YARN和Mesos等流行的集群资源管理器之上。

## 为什么要整合SparkSQL和Hive
SparkSQL操作Hive中的表数据
Spark可以通过读取hive的元数据来兼容hive，读取hive的表数据，然后在spark引擎中进行sql统计分析，从而，通过sparksql与hive结合实现数据分析将成为一种最佳实践。  、

## 为什么需要Flink   
**计算速度的需求**  
大数据的4代计算引擎   
第1代： Hadoop MapReduc批处理 Mapper、Reducer 2.   
第2代： DAG框架（Oozie 、Tez），Tez + MapReduce 批处理 1个Tez = MR(1) + MR(2) + ... + MR(n) 相比MR效率有所提升   
第3代： Spark 批处理、流处理、SQL高层API支持 自带DAG 内存迭代计算、性能较之前大幅提  
第4代： Flink 批处理、流处理、SQL高层API支持 自带DAG 流式计算性能更高、可靠性更高  

Spark和Flink全部都运行在Hadoop YARN上，  
性能为Flink > Spark > Hadoop(MR)，迭代次数越多越明显，  
性能上，Flink优于Spark和Hadoop最主要的原因是Flink支持增量迭代，具有对迭代自动优化的功能。  
