# 大数据各组件存在的意义  

## 为什么需要HDFS  
随着区块链、大数据等技术的推动，全球数据量正在无限制地扩展和增加。  
随着数据量越来越大，在一个操作系统存不下所有的数据，那么就分配到更多的操作系统管理的磁盘中，但是不方便管理和维护，迫切需要一种系统来管理多台机器上的文件，这就是分布式文件管理系统。HDFS只是分布式文件管理系统中的一种。  


## 为什么需要HBase
* Hadoop已经有了HDFS和MR，为什么还需要HBase？  
	* MR可以很好的解决大规模数据离线批量处理的问题，但是只能以顺序方式访问数据，实时性很差
	* 需要一个新的解决方案，能够随机访问数据中的任何单元----Hadoop随机存取数据库HBase

* 为什么不用传统的关系型数据库？
	* 传统的通用关系型数据库无法应对数据规模剧增时导致的系统扩展性和性能问题，分库分表也不能很好的解决
	* 传统的关系型数据库在数据结构发生变化时，一般需要停机维护，空列也会浪费存储空间  
**HDFS数据不方便日常使用，查询也慢**

## 为什么需要Hive 
1. HDFS解决分布式存储问题，MR解决分布式计算问题
但是学习过程很痛苦，需要一定的编程基础-JAVA,Linux，MR编程，MR套路和原理  
在Hadoop编程过程中，在解决计算问题的时候，基本都是针对结构化数据，事实上在实际生产过程中接触到的数据比如日志数据，是比较规整的结构化数据，针对结构化数据最好的分析方式是SQL  
比如JION操作，实现两表的关联
如果使用MR编程，至少要写60行代码
如果使用SQL只需一行：
select * from a join b on a.pid = b.pid 

## 为什么要整合Hbase和Hive  
* hive和Hbase的整合使得hive能够操作Hbase的数据表  
	* Hive是建立在Hadoop之上的数据仓库基础构架、是为了减少MapReduce编写工作的批处理系统，Hive本身不存储和计算数据，它完全依赖于HDFS和MapReduce。Hive可以理解为一个客户端工具，将我们的sql操作转换为相应的MapReduce jobs，然后在Hadoop上面运行。   
	* HBase全称为Hadoop Database，即HBase是Hadoop的数据库，是一个分布式的存储系统。HBase利用Hadoop的HDFS作为其文件存储系统，利用Hadoop的MapReduce来处理HBase中的海量数据。利用Zookeeper作为其协调工具。   
	* HBase数据库的缺点在于——语法格式异类，没有类sql的查询方式，因此在实际的业务当中操作和计算数据非常不方便，但是Hive就不一样了，Hive支持标准的sql语法，于是我们就希望通过Hive这个客户端工具对HBase中的数据进行操作与查询，进行相应的数据挖掘，这就是所谓Hive与hBase整合的含义。  

## 为什么要整合SparkSQL和Hive
SparkSQL操作Hive中的表数据
Spark可以通过读取hive的元数据来兼容hive，读取hive的表数据，然后在spark引擎中进行sql统计分析，从而，通过sparksql与hive结合实现数据分析将成为一种最佳实践。
