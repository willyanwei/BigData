# HIVE  


## 大数据学习线路图  
<img src="https://upload-images.jianshu.io/upload_images/22827736-ab17271698b9385a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="70%">
  
  


## 什么是Hive  
1. 由Facebook开源，最初用于解决海量结构化的日志数据统计问题，贡献给了apache基金会  

2. 底层数据存储在HDFS上   
基于Hadoop的一个数据仓库工具，底层仍然是Hadoop  
Hive仅是数据管理的作用，并不会进行数据存储  

3. 通过元数据关联Hive表与HDFS数据
Hive想要管理HDFS数据，就要建立一个关联关系，关联Hive上的表和HDFS上的数据路径  
这个数据依赖一个元数据库记录，一般情况下这个元数据采用关系型数据库，一般使用mysql作为Hive的元数据库（Hive中内置默认的元数据库derby）  

> 元数据  
> Hive中的表和HDFS上数据的映射关系  
> Hive表属性-内部表，外部表，视图  
> 字段信息-字段类型，字段顺序  
> 元数据一旦丢失，整个Hive库和表都会消失   
 

4. 提供类SQL查询功能  
将结构化数据文件映射为一张表数据库表，将结构化数据（每一行上列比较规整的数据）映射为二维表  
将文本中的每一行数据映射为数据库的每一条数据  
将文本中的每一列数据映射为Hive表字段  

5. 将SQL转化成MR任务的工具  
其本质是将SQL转换成MR的任务进行计算，甚至可以说Hive是MR的一个客户端  
Hive库中存储了很多MR模板，当用户执行一条SQL时，会被翻译成MR任务执行  

6. 使不熟悉MR的用户也能很方便的使用HSQL处理和计算HDFS上的结构化数据
7. 适用离线的批量处理  

## 为什么需要Hive 


1. HDFS解决分布式存储问题，MR解决分布式计算问题
但是学习过程很痛苦，需要一定的编程基础-JAVA,Linux，MR编程，MR套路和原理  
在Hadoop编程过程中，在解决计算问题的时候，基本都是针对结构化数据，事实上在实际生产过程中接触到的数据比如日志数据，是比较规整的结构化数据，针对结构化数据最好的分析方式是SQL  
比如JION操作，实现两表的关联
如果使用MR编程，至少要写60行代码
如果使用SQL只需一行：
select * from a join b on a.pid = b.pid 


## Hive的优缺点  
* 优点  
	* 可扩展性强  
	Hive可以自由的扩展集群的规模，一般情况下不需要重启服务  
	横向扩展：通过分担压力的方式扩展集群的规模  
	纵向扩展：服务器配置升级，CPU内存等  
	* 延展性  
	支持自定义函数，可以根据自己的需求来实现自己的函数  
	* 容错性  
	可以保证及时有节点出现问题，SQL语句仍可完成执行  

* 缺点  
	* 不支持记录级别的增删改操作  
	但是用户可以通过查询生成的新表或者将查询结果导入到文件中  
	* 延迟大  
	MR的启动过程消耗很长时间，所以不能用在交互查询系统中  
	* 不支持事务  
	因为没有增删改，所以只要用来做OLAP而不是OLTP

> OLTP? OLAP?  
> OLTP（on-line transaction processing）翻译为联机事务处理，   
> OLAP（On-Line Analytical Processing）翻译为联机分析处理，  
> 从字面上来看OLTP是做事务处理，OLAP是做分析处理。  
> 从对数据库操作来看，OLTP主要是对数据的增删改，OLAP是对数据的查询。  


## Hive架构  
* 用户接口层
	* CLI-Command line interface  shell命令行
	* JDBC/ODBC是Hive的JAVA实现，有传统的JDBC类似
	* WebGUI 通过浏览器访问Hive
* 元数据存储  
	* 通常存储在关系型数据库如mysql/derby中  
	* Hive中的元数据包括表的名字，表的列，分区及其属性（是否为外部表），表的数据所在目录
* Thrift服务器  
	* 用来提供一个跨语言的服务，Java等各种语言操作Hive  
* 驱动层  
	完成HQL查询语句从词法分析、语法分析、编译、优化以及查询计划生成。
	生成的查询计划存储在HDFS中，并随后由MR调用执行  
	* 编译器  
	驱动整个HQL的运行，HQL语句解析为MR程序，最终将MR程序提交到Hadoop  
	* 优化器  
	在编译过程中肯定会有很多SQL转化成MR程序，存在包含关系、重复的操作，在优化器中可以将重复的操作过滤掉  
	* 执行器  
	将SQL语句通过Hive自带的MR模板，编译成MR程序，首先生成一个逻辑执行计划，再生成一个物理执行计划  

<img src="https://upload-images.jianshu.io/upload_images/22827736-c7ea6a9f54847c96.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="70%">


<img src="https://upload-images.jianshu.io/upload_images/22827736-9b9dbf616afb017a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="70%">



## Hive的数据组成  
* 库  DataBase  
* 表
	* 内部表     
	存储位置： General->Hive Metastore Warehouse directory->/warehouse/tablespace/managed/hive  
	* 外部表    
	存储位置： Advanced hive-site->Hive Metastore Warehouse External directory->/warehouse/tablespace/external/hive  
		* 内部表和外部表是两个相对的概念，区别在于删除表时是否删除数据  
		* 内部表删除表时会删除数据和元数据   
		* 外部表删除表时只会删除元数据  
		* 一般存储公共数据的表存放为外部表

	* 分区表  
		* Hive存储海量数据，海量的数据查询一定要注意避免全表扫描
		* 查询时为了提升查询性能，设计了分区表，将数据按照用户的业务存储到不同的目录下
		* 一般用日期作为分段字段  
		> 北京  天津  石家庄  深圳  
		> 假设我们存储在一个普通表City中，每次查询都需要进行全表扫描，性能不高  
		> 普通表：  
		> /Hive/warehouse/log.txt  
		> 分区表：存储的指定不同目录就是分区字段    
		> /Hive/warehouse/city=beijing/log_beijing.txt   
		> /Hive/warehouse/city=tianjin/log_tianjin.txt   
		> /Hive/warehouse/city=shijiazhuang/log_shijiazhuang.txt   
		> /Hive/warehouse/city=shenzhen/shenzhen.txt   
		> 在执行数据查询时只会对指定分区进行查询  
		> select * from stu where city = beijing  
	* 分桶表
		类似于Hadoop中的分区，程序决定的，只能指定桶的个数（分区的个数）  
		根据hash算法，将余数不同的输出到不同的文件中    
		> /Hive/warehouse/part-r-00000  
		> /Hive/warehouse/part-r-00001  
		> /Hive/warehouse/part-r-00002  
		
		作用：    
		提升join的性能    
		提升数据样本的抽取效率，直接拿桶中的数据作为样本数据    
* 视图  
	* 在Hive中仅仅存在逻辑视图不存在物理视图  
	* 物理视图：将SQL语句的执行结果存储在视频中  
	create view my_view as select id, name, sex from stu; -------别名 
	select * from my_view;  -------视图执行   
* 数据存储  
	* 原始数据存储在HDFS上
	* 元数据存储在MySQL中

## Hive的登录方式

* bin/hive

* 使用SQL语句或者SQL脚本进行交互

* 把Hive进程挂载到后台或者前台（推荐）

* 客户端Dbeaver

## Hive的基本操作  
* 数据库操作
* 数据表操作
	* 外部表
	* 内部表
	* 分区表
	* 分桶表

## Hive的元数据和表数据存储

* 元数据存储  
元数据的存储主要有两种方式：第一种是使用hive自带的derby数据库进行元数据的存储；第二种是使用mysql数据库来进行hive元数据的存储;  
下面以mysql为例，解析Hive中的元数据表。  
登录mysql： mysql -u root -p Bigdata_123
Hive元数据库中一些重要的表结构及用途，方便Impala、SparkSQL、Hive等组件访问元数据库的理解。  
	* 存储Hive版本的元数据表(VERSION)  


	* Hive数据库相关的元数据表(DBS、DATABASE_PARAMS)  
	DBS：该表存储Hive中所有数据库的基本信息，字段如下:
	DATABASE_PARAMS：该表存储数据库的相关参数，在CREATE DATABASE时候用WITH DBPROPERTIES(property_name=property_value, …)指定的参数。

	* Hive表和视图相关的元数据表  
	主要有TBLS、TABLE_PARAMS、TBL_PRIVS，这三张表通过TBL_ID关联。  
	TBLS:该表中存储Hive表，视图，索引表的基本信息  
	TABLE_PARAMS:该表存储表/视图的属性信息  
	TBL_PRIVS：该表存储表/视图的授权信息

	* Hive文件存储信息相关的元数据表  
	主要涉及SDS、SD_PARAMS、SERDES、SERDE_PARAMS，由于HDFS支持的文件格式很多，而建Hive表时候也可以指定各种文件格式，Hive在将HQL解析成MapReduce时候，需要知道去哪里，使用哪种格式去读写HDFS文件，而这些信息就保存在这几张表中。  
	SDS:该表保存文件存储的基本信息，如INPUT_FORMAT、OUTPUT_FORMAT、是否压缩等。TBLS表中的SD_ID与该表关联，可以获取Hive表的存储信息。  
	SD_PARAMS: 该表存储Hive存储的属性信息，在创建表时候使用STORED BY‘storage.handler.class.name’ [WITH SERDEPROPERTIES (…)指定。  
	SERDES:该表存储序列化使用的类信息  
	SERDE_PARAMS:该表存储序列化的一些属性、格式信息，比如:行、列分隔符

	* Hive表字段相关的元数据表  
	主要涉及COLUMNS_V2  
	COLUMNS_V2：该表存储表对应的字段信息

	* Hive表分分区相关的元数据表  
	主要涉及PARTITIONS、PARTITION_KEYS、PARTITION_KEY_VALS、PARTITION_PARAMS  
	PARTITIONS:该表存储表分区的基本信息  
	PARTITION_KEYS:该表存储分区的字段信息  
	PARTITION_KEY_VALS:该表存储分区字段值  
	PARTITION_PARAMS:该表存储分区的属性信息

	* 其他不常用的元数据表  
	DB_PRIVS：数据库权限信息表。通过GRANT语句对数据库授权后，将会在这里存储。  
	IDXS：索引表，存储Hive索引相关的元数据  
	INDEX_PARAMS：索引相关的属性信息  
	TBL_COL_STATS：表字段的统计信息。使用ANALYZE语句对表字段分析后记录在这里  
	TBL_COL_PRIVS：表字段的授权信息  
	PART_PRIVS：分区的授权信息  
	PART_COL_PRIVS：分区字段的权限信息  
	PART_COL_STATS：分区字段的统计信息  
	FUNCS：用户注册的函数信息  
	FUNC_RU：用户注册函数的资源信息

* 表数据存储  
1、内部表数据由Hive自身管理，外部表数据由HDFS管理；  
2、内部表数据存储的位置是hive.metastore.warehouse.dir（默认：/user/hive/warehouse）；  
3、外部表数据的存储位置由自己制定（如果没有LOCATION，Hive将在HDFS上的/user/hive/warehouse文件夹下以外部表的表名创建一个文件夹，并将属于这个表的数据存放在这里）；  
4、未被external修饰的是内部表（managed table），被external修饰的为外部表（external table）；  
5、删除内部表会直接删除元数据（metadata）及存储数据；删除外部表仅仅会删除元数据，HDFS上的文件并不会被删除；  
6、对内部表的修改会将修改直接同步给元数据，而对外部表的表结构和分区进行修改，则需要修复（MSCK REPAIR TABLE table_name;）    

## 案例一
* Wordcount案例
	* 建表  
create table docs(line string);  
	* 加载数据到表里  
load data local inpath '/hadoop/hadoop2.9/word.txt' into table docs;  
load data inpath 'hdfs://test/word.txt' into table docs  
	* 按照空格切割查询,形成数组  
select split(line,' ') from docs;  
执行  
hive> select split(line,' ') from docs;  
OK  
["from","cell_monitor","cm","",""]  
["insert","overwrite","table","cell_drop_monitor"]  
[""]  
["from","cell_monitor","cm","",""]  
["insert",""]  

	* explode(array) 数组一条记录有多个参数,将参数拆分,每个参数生成一列  
hive> select explode(split(line,' '))from docs;  
OK  
from  
cell_monitor  
cm  


		insert  
overwrite  
table  
cell_drop_monitor  

		from  
cell_monitor  
cm  

	* 创建结果表  
create table wc(word string,totalword int);  

	* 统计SQL语句  
from (select explode(split(line,' ')) as word from docs) w insert into table wc    
select word, count(1) as totalword  
group by word  
order by word;  

	* 结果  
hive> select * from wc;  
OK  
cell_drop_monitor	1  
cell_monitor	2  
cm	2  
from	2  
insert	2  
overwrite	1  
table	1  
Time taken: 0.18 seconds, Fetched: 8 row(s)      

## 案例二  
* 首先下载测试数据，数据也可以创建   
http://files.grouplens.org/datasets/movielens/ml-latest-small.zip  

	数据类型与字段名称  
	movies.csv（电影元数据）  
	movieId,title,genres  
	ratings.csv（用户打分数据）  
	userId,movieId,rating,timestamp  

* 先把数据存放到HDFS上  
	hadoop fs -mkdir /case/film      
	hadoop fs -mkdir /case/film/movie_table  
	hadoop fs -mkdir /case/film/rating_table    
	hadoop fs -put movies.csv /case/film/movie_table    
	hadoop fs -put ratings.csv /case/film/rating_table    

* 创建movie_table和rating_table  
	drop table if exists hive_movie_table;  

	create external table hive_movie_table  
	(  
	movieId STRING,  
	title STRING,  
	genres STRING  
	)  
	row format delimited fields terminated by ','  
	stored as textfile  
	location '/test/moviesdata/movies';  

	drop table if exists hive_rating_table;  

	create external table rating_table  
	(userId STRING,  
	movieId STRING,  
	rating STRING,  
	ts STRING  
	)  
	row format delimited fields terminated by ','  
	stored as textfile
	location '/test/moviesdata/ratings';  

	其中字段名为timestamp为hive的保留字段，执行的时候会报错，需用反引号或者修改字段名，我这边修改的字段名  


* 查看表
	hive> show tables;  
	OK  
	movie_table    
	rating_table  

	hive> select * from rating_table limit 10;    
	OK
	1312.51260759144110293.01260759179110613.01260759182111292.01260759185111724.01260759205112632.01260759151112872.01260759187112932.01260759148113393.51260759125113432.01260759131

* 扩展 
	生成新表(行为表)
	create table behavior_table as

	select B.userid, A.movieid, B.rating, A.title
	from movie_table A
	join rating_table B
	on A.movieid == B.movieid;

	把Hive表数据导入到本地  
	table->local file
	insert overwrite local directory '/opt/case/tmp/1.txt'
	Select * from movie_table;

	把Hive表数据导入到HDFS上  
	table->hdfs file
	insert overwrite directory '/case/film/tmp/1.txt'
	Select * from movie_table;

	把本地数据导入到Hive表中
	local file -> table
	LOAD DATA LOCAL INPATH '/root/hive_test/a.txt'OVERWRITE INTO TABLE behavior_table;

	把HDFS上的数导入到HIve表中 
	hdfs file -> table
	LOAD DATA INPATH '/a.txt' OVERWRITE INTO TABLE behavior_table;

	管理表与外部表互换
	1）查询表的类型
	hive>desc formatted behavior_table;
	2）修改内部表 behavior_table 为外部表
	alter table behavior_table set tblproperties('EXTERNAL'='TRUE');
	3）修改外部表 behavior_table 为内部表
	alter table behavior_table set tblproperties('EXTERNAL'='FALSE');
	注意：('EXTERNAL'='TRUE')和('EXTERNAL'='FALSE')为固定写法，区分大小写！






# HIVE 和 Hbase 整合
## 为什么要整合
* hive和Hbase的整合使得hive能够操作Hbase的数据表  
	* Hive是建立在Hadoop之上的数据仓库基础构架、是为了减少MapReduce编写工作的批处理系统，Hive本身不存储和计算数据，它完全依赖于HDFS和MapReduce。Hive可以理解为一个客户端工具，将我们的sql操作转换为相应的MapReduce jobs，然后在Hadoop上面运行。   
	* HBase全称为Hadoop Database，即HBase是Hadoop的数据库，是一个分布式的存储系统。HBase利用Hadoop的HDFS作为其文件存储系统，利用Hadoop的MapReduce来处理HBase中的海量数据。利用Zookeeper作为其协调工具。   
	* HBase数据库的缺点在于——语法格式异类，没有类sql的查询方式，因此在实际的业务当中操作和计算数据非常不方便，但是Hive就不一样了，Hive支持标准的sql语法，于是我们就希望通过Hive这个客户端工具对HBase中的数据进行操作与查询，进行相应的数据挖掘，这就是所谓Hive与hBase整合的含义。


	> 整合后：   
	> select * from table   
	> group by word    
	> order by word;
## 整合的案例  
* 打开xshell的两个命令窗口
一个进入hive，一个进入hbase
root@101Server:/opt/hive3.1/lib# hive  

root@101Server:/opt/hbase2.4/bin# hbase shell

在hive中创建映射hbase的表
在hive中创建一个映射hbase的表，为了方便，设置两边的表名都为t_student，存储的表也是这个。

在hive中输入:
create table HiveHBase_Student(id int,name string)

stored by'org.apache.hadoop.hive.hbase.HBaseStorageHandler'

with

serdeproperties("hbase.columns.mapping"=":key,st1:name")

tblproperties("hbase.table.name"="HiveHBase_Student","hbase.mapred.output.outputtable"= "HiveHBase_Student");

 

说明： 
第一个t_student 是hive表中的名称，  
第二个t_student是定义在hbase的table名称 ，  
第三个t_student 是存储数据表的名称("hbase.mapred.output.outputtable" = "t_student"这个可以不要，表数据就存储在第二个表中了) 。

(id int,name string) 这个是hive表结构。如果要增加字段，就以这种格式增加。如果要增加字段的注释，那么在字段后面添加comment ‘你要描述的’。

例如:

create table t_student(id int comment ‘StudentId’,name string comment ‘StudentName’)

org.apache.hadoop.hive.hbase.HBaseStorageHandler 这个是指定的存储器。

hbase.columns.mapping 是定义在hbase的列族。

例如:st1就是列族，name就是列。在hive中创建表t_student，这个表包括两个字段（int型的id和string型的name）。 映射为hbase中的表t_student，key对应hbase的rowkey，value对应hbase的st1:name列。

* 表成功创建之后
在hive、hbase分别中查看表和表结构

hive中输入

show tables；
describe HiveHBase_Student;

hbase输入:

list
describe ‘HiveHBase_Student’

可以看到表已经成功的创建了

 
* 数据同步测试
进入hbase之后

在t_student中添加两条数据 然后查询该表

put 'HiveHBase_Student','1001','st1:name','zhangsan'

put 'HiveHBase_Student','1002','st1:name','lisi'

scan 'HiveHBase_Student'

 

hbase:011:0> scan 't_student'

ROW                           COLUMN+CELL

 1001                         column=st1:name, timestamp=2022-03-23T18:20:34.212, value=zhangsan

 1002                         column=st1:name, timestamp=2022-03-23T18:21:05.592, value=lisi\x0A\x0A\x0A\x0A

2 row(s)

Took 0.1101 seconds



然后切换到hive中

查询该表

输入:

select* fromt_student;

 

hive> select * from t_student;

OK

1001    zhangsan

1002    lisi

 

Time taken: 1.697 seconds, Fetched: 2 row(s)

 

在hive中删除该表
注:因为做测试要看结果，所以将表删除了。如果同学们要做测试的话，是没有必要删除该表的，因为在后面还会使用该表。

然后查看hive和hbase中的表是否删除了

输入:

drop table t_student;

 

* 关联查询测试
hive外部表测试

先在hbase中建一张t_student_info表，添加两个列族

然后查看表结构

输入:

create't_student_info','st1','st2'describe't_student_info'

 

然后在hive中创建外部表

说明:创建外部表要使用EXTERNAL 关键字

输入:

createexternaltablet_student_info(id int,age int,sex string)

Stored by

'org.apache.hadoop.hive.hbase.HBaseStorageHandler'

With

serdeproperties("hbase.columns.mapping"=":key,st1:age,st2:sex") tblproperties("hbase.table.name"="t_student_info");

 

然后在t_student_info 中添加数据

put 't_student_info','1001','st2:sex','man'

put 't_student_info','1001','st1:age','20'

put 't_student_info','1002','st1:age','18' 

put 't_student_info','1002','st2:sex','woman'

 

然后在hive中查询该表

输入:

select* fromt_student_info;

 

查询到数据之后，然后将t_student 和t_student_info进行关联查询。

输入:

Select * from t_student t join t_student ti where t.id=ti.id ;

 

说明:通过关联查询，可以得出表之间是可以关联查询的。但是明显看到hive 使用默认的mapreduce 作为引擎是多么的慢。。。 
在查询一张表的时候，hive没有使用引擎，因此相对比较快，如果是进行了关联查询之类的，就会使用引擎，由于hive默认的引擎是mr，所以会很慢，也和配置有一定关系，hive2.x以后官方就不建议使用mr了。  
